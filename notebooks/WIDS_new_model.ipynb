{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "fFIkGmsVh1lg",
        "outputId": "2a9ffa91-a23d-42c4-a79b-3e788e66d21c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Packet Size</th>\n",
              "      <th>Packet Length</th>\n",
              "      <th>Inter-Arrival Time</th>\n",
              "      <th>Protocol Type</th>\n",
              "      <th>Flags</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Packets</th>\n",
              "      <th>Total Bytes</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>...</th>\n",
              "      <th>Baseline Deviation</th>\n",
              "      <th>Packet Size Variance</th>\n",
              "      <th>Known IoC</th>\n",
              "      <th>C&amp;C Communication</th>\n",
              "      <th>Data Exfiltration</th>\n",
              "      <th>Label</th>\n",
              "      <th>Threat Intensity</th>\n",
              "      <th>Base Risk</th>\n",
              "      <th>Modifier</th>\n",
              "      <th>Final Risk Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-11-01 00:00:00</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>TCP</td>\n",
              "      <td>ACK</td>\n",
              "      <td>0.920496</td>\n",
              "      <td>150.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>533.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038337</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Ransomware</td>\n",
              "      <td>High</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-11-01 01:00:00</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>TCP</td>\n",
              "      <td>SYN</td>\n",
              "      <td>6.637806</td>\n",
              "      <td>150.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>533.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.166918</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Benign</td>\n",
              "      <td>Medium</td>\n",
              "      <td>0.66</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-11-01 02:00:00</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>TCP</td>\n",
              "      <td>SYN</td>\n",
              "      <td>5.666317</td>\n",
              "      <td>150.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>533.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.083234</td>\n",
              "      <td>251.082387</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Benign</td>\n",
              "      <td>Medium</td>\n",
              "      <td>0.66</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-11-01 03:00:00</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>TCP</td>\n",
              "      <td>FIN</td>\n",
              "      <td>4.166854</td>\n",
              "      <td>150.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>533.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.221439</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Benign</td>\n",
              "      <td>Medium</td>\n",
              "      <td>0.66</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-11-01 04:00:00</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>TCP</td>\n",
              "      <td>FIN</td>\n",
              "      <td>2.179507</td>\n",
              "      <td>150.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>533.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034485</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Benign</td>\n",
              "      <td>Low</td>\n",
              "      <td>0.33</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Timestamp  Packet Size  Packet Length  Inter-Arrival Time  \\\n",
              "0  2019-11-01 00:00:00       1500.0         1400.0                0.01   \n",
              "1  2019-11-01 01:00:00       1500.0         1400.0                0.01   \n",
              "2  2019-11-01 02:00:00       1500.0         1400.0                0.01   \n",
              "3  2019-11-01 03:00:00       1500.0         1400.0                0.01   \n",
              "4  2019-11-01 04:00:00       1500.0         1400.0                0.01   \n",
              "\n",
              "  Protocol Type Flags  Flow Duration  Total Packets  Total Bytes  \\\n",
              "0           TCP   ACK       0.920496          150.0      80000.0   \n",
              "1           TCP   SYN       6.637806          150.0      80000.0   \n",
              "2           TCP   SYN       5.666317          150.0      80000.0   \n",
              "3           TCP   FIN       4.166854          150.0      80000.0   \n",
              "4           TCP   FIN       2.179507          150.0      80000.0   \n",
              "\n",
              "   Average Packet Size  ...  Baseline Deviation  Packet Size Variance  \\\n",
              "0           533.333333  ...            0.038337            600.000000   \n",
              "1           533.333333  ...            0.166918            600.000000   \n",
              "2           533.333333  ...            0.083234            251.082387   \n",
              "3           533.333333  ...            0.221439            600.000000   \n",
              "4           533.333333  ...            0.034485            600.000000   \n",
              "\n",
              "   Known IoC  C&C Communication  Data Exfiltration       Label  \\\n",
              "0          0                  0                  0  Ransomware   \n",
              "1          0                  0                  1      Benign   \n",
              "2          0                  0                  0      Benign   \n",
              "3          0                  0                  0      Benign   \n",
              "4          0                  0                  0      Benign   \n",
              "\n",
              "   Threat Intensity  Base Risk Modifier Final Risk Score  \n",
              "0              High       1.00     0.00             1.00  \n",
              "1            Medium       0.66    -0.33             0.33  \n",
              "2            Medium       0.66    -0.33             0.33  \n",
              "3            Medium       0.66    -0.33             0.33  \n",
              "4               Low       0.33    -0.33             0.00  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('IIoT_Malware_Timeseries_CLEAN.csv') #creating pandas dataframe from the csv\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ESWUaQvkiDmm"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['Protocol Type', 'Flags'] #category columns\n",
        "numerical_cols = ['Packet Size', 'Packet Length', 'Inter-Arrival Time','Flow Duration', 'Total Packets', 'Total Bytes',\n",
        "    'Average Packet Size', 'Packet Arrival Rate',\n",
        "    'Payload Entropy', 'Flow Entropy', 'Baseline Deviation', 'Packet Size Variance',\n",
        "    'Known IoC', 'C&C Communication', 'Data Exfiltration'] #numerical columns\n",
        "target_col= 'Label' #target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p-j8KMWjLmA",
        "outputId": "7b8c5506-4795-4434-fab4-08750f366234"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((45289, 25), (45289,))"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_cats = ohe.fit_transform(df[categorical_cols])\n",
        "encoded_cat_columns = ohe.get_feature_names_out(categorical_cols)\n",
        "df_encoded_cats = pd.DataFrame(encoded_cats, columns=encoded_cat_columns)\n",
        "df_encoded_cats.index = df.index\n",
        "df_numerical = df[numerical_cols]\n",
        "x = pd.concat([df_numerical, df_encoded_cats], axis=1)\n",
        "y = df[target_col]\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEtwf2vWmfWI",
        "outputId": "3aeadbd4-c8f5-41a8-e380-ffd75a5f15d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size is : (36231, 25)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2, random_state=42, stratify=y)\n",
        "print(f'Train size is : {x_train.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "PvZlRgpbngIG",
        "outputId": "9d238ff0-a63c-4de6-9ed8-1c4a57bc8101"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      3\u001b[39m model= RandomForestClassifier(n_estimators=\u001b[32m700\u001b[39m, max_depth= \u001b[32m23\u001b[39m, random_state= \u001b[32m42\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1145\u001b[39m     estimator._validate_params()\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1148\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1149\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1150\u001b[39m     )\n\u001b[32m   1151\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    352\u001b[39m     sample_weight = _check_sample_weight(sample_weight, X)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:622\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    620\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m     out = X, y\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1141\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1143\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1144\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1164\u001b[39m check_consistent_length(X, y)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:957\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    952\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    953\u001b[39m             % (array.ndim, estimator_name)\n\u001b[32m    954\u001b[39m         )\n\u001b[32m    956\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples > \u001b[32m0\u001b[39m:\n\u001b[32m    965\u001b[39m     n_samples = _num_samples(array)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:122\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:171\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    156\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    157\u001b[39m     msg_err += (\n\u001b[32m    158\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
            "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model= RandomForestClassifier(n_estimators=700, max_depth= 23, random_state= 42, n_jobs=-1, class_weight='balanced' )\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BStGaZUOoFwM",
        "outputId": "18c68564-3735-4fbc-b830-7c284d820d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is 0.6917641863546037\n",
            "classification report is               precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.70      0.99      0.82      6324\n",
            "      Botnet       0.06      0.00      0.00       546\n",
            "  Ransomware       0.03      0.00      0.00       739\n",
            "     Spyware       0.20      0.01      0.01       649\n",
            "      Trojan       0.14      0.01      0.01       449\n",
            "        Worm       0.10      0.00      0.01       351\n",
            "\n",
            "    accuracy                           0.69      9058\n",
            "   macro avg       0.20      0.17      0.14      9058\n",
            "weighted avg       0.52      0.69      0.57      9058\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"Accuracy is\", accuracy_score(y_test, y_pred))\n",
        "print(\"classification report is\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qYEgsfnKpk9",
        "outputId": "e43471cd-4942-4037-e19f-036cacc191f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original X_train shape: (36231, 25)\n",
            "Resampled X_train shape: (151782, 25)\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "x_train = x_train.fillna(0)\n",
        "x_train_smote, y_train_smote = smote.fit_resample(x_train,y_train)\n",
        "print(\"Original X_train shape:\", x_train.shape)\n",
        "print(\"Resampled X_train shape:\", x_train_smote.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kWdY5FKLe6T"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=23, n_estimators=700,\n",
              "                       n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=23, n_estimators=700,\n",
              "                       n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_depth=23, n_estimators=700,\n",
              "                       n_jobs=-1, random_state=42)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model= RandomForestClassifier(n_estimators=1500, max_depth= 23, random_state= 42, n_jobs=-1, class_weight='balanced' )\n",
        "model.fit(x_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is 0.554979024067123\n",
            "Classification report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.70      0.77      0.73      6324\n",
            "      Botnet       0.07      0.03      0.05       546\n",
            "  Ransomware       0.08      0.06      0.07       739\n",
            "     Spyware       0.08      0.05      0.07       649\n",
            "      Trojan       0.05      0.07      0.06       449\n",
            "        Worm       0.03      0.02      0.02       351\n",
            "\n",
            "    accuracy                           0.55      9058\n",
            "   macro avg       0.17      0.17      0.17      9058\n",
            "weighted avg       0.51      0.55      0.53      9058\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "x_test = x_test.fillna(0)\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(\"Accuracy is\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification report is\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_xgb = xgb.XGBClassifier(\n",
        "    tree_method='gpu_hist',\n",
        "    predictor='gpu_predictor',\n",
        "    n_estimators=1000,        \n",
        "    max_depth=7,              \n",
        "    learning_rate=0.05,        \n",
        "    gamma=5.0,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    reg_alpha = 1.0,\n",
        "    reg_lambda=1.0,\n",
        "    use_label_encoder=False,\n",
        "    objective='multi:softprob',\n",
        "    eval_metric='mlogloss'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "\n",
        "le.fit(pd.concat([y_train, y_test]))\n",
        "\n",
        "\n",
        "y_train_smote_enc = le.transform(y_train_smote)\n",
        "y_test_enc = le.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:10:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:10:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=5.0,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
              "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=5.0,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
              "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='mlogloss',\n",
              "              feature_types=None, feature_weights=None, gamma=5.0,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
              "              num_parallel_tree=None, ...)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_xgb.fit(x_train_smote, y_train_smote_enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:11:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy is 0.5973724884080371\n",
            "XGBoost Classification report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.84      0.76      6324\n",
            "           1       0.09      0.03      0.04       546\n",
            "           2       0.10      0.03      0.05       739\n",
            "           3       0.04      0.01      0.02       649\n",
            "           4       0.06      0.08      0.07       449\n",
            "           5       0.04      0.03      0.04       351\n",
            "\n",
            "    accuracy                           0.60      9058\n",
            "   macro avg       0.17      0.17      0.16      9058\n",
            "weighted avg       0.51      0.60      0.55      9058\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred_xgb = model_xgb.predict(x_test)\n",
        "\n",
        "\n",
        "y_pred_labels = le.inverse_transform(y_pred_xgb)\n",
        "\n",
        "\n",
        "print(\"XGBoost Accuracy is\", accuracy_score(y_test_enc, y_pred_xgb))\n",
        "print(\"XGBoost Classification report is\\n\", classification_report(y_test_enc, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train distribution: Counter({'Benign': 20237, 'Ransomware': 2363, 'Spyware': 2076, 'Botnet': 1747, 'Trojan': 1438, 'Worm': 1123})\n",
            "Valid distribution: Counter({'Benign': 5060, 'Ransomware': 591, 'Spyware': 519, 'Botnet': 437, 'Trojan': 359, 'Worm': 281})\n",
            "\n",
            "=== Class 'Benign' detector ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Recall for 'Benign': 1.00 @ threshold 0.13\n",
            "\n",
            "=== Class 'Botnet' detector ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Recall for 'Botnet': 1.00 @ threshold 0.00\n",
            "\n",
            "=== Class 'Ransomware' detector ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Recall for 'Ransomware': 1.00 @ threshold 0.00\n",
            "\n",
            "=== Class 'Spyware' detector ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Recall for 'Spyware': 1.00 @ threshold 0.00\n",
            "\n",
            "=== Class 'Trojan' detector ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Recall for 'Trojan': 1.00 @ threshold 0.00\n",
            "\n",
            "=== Class 'Worm' detector ===\n",
            "✅  Recall for 'Worm': 1.00 @ threshold 0.00\n",
            "\n",
            "### Summary of per-family recall and thresholds ###\n",
            "Benign       → recall: 1.00, threshold: 0.12675392627716064\n",
            "Botnet       → recall: 1.00, threshold: 0.00029300080495886505\n",
            "Ransomware   → recall: 1.00, threshold: 0.00039489701157435775\n",
            "Spyware      → recall: 1.00, threshold: 0.00023535384389106184\n",
            "Trojan       → recall: 1.00, threshold: 5.238258381723426e-05\n",
            "Worm         → recall: 1.00, threshold: 0.00010967328125843778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import precision_recall_curve, recall_score\n",
        "\n",
        "\n",
        "print(\"Train distribution:\", Counter(y_train))\n",
        "print(\"Valid distribution:\", Counter(y_valid))\n",
        "\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "best_recall = {}\n",
        "best_thresh = {}\n",
        "\n",
        "\n",
        "for label in classes:\n",
        "    print(f\"\\n=== Class '{label}' detector ===\")\n",
        "    \n",
        "    \n",
        "    y_bin     = (y_train == label).astype(int)\n",
        "    y_val_bin = (y_valid == label).astype(int)\n",
        "    \n",
        "    \n",
        "    if y_bin.sum() == 0:\n",
        "        print(f\"❌  No training samples for '{label}' → skipped\")\n",
        "        best_recall[label] = 0.0\n",
        "        best_thresh[label] = None\n",
        "        continue\n",
        "\n",
        "    \n",
        "    x_res, y_res = sm.fit_resample(x_train, y_bin)\n",
        "\n",
        "  \n",
        "    neg, pos = np.bincount(y_res)\n",
        "    pos_weight = neg / pos\n",
        "\n",
        "    \n",
        "    clf = XGBClassifier(\n",
        "        tree_method='gpu_hist',\n",
        "        predictor='gpu_predictor',\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        scale_pos_weight=pos_weight,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=500,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    clf.fit(x_res, y_res)\n",
        "\n",
        "\n",
        "    probs = clf.predict_proba(x_valid)[:, 1]\n",
        "    p, r, t = precision_recall_curve(y_val_bin, probs)\n",
        "    idxs = np.where(r >= 0.5)[0]\n",
        "    if len(idxs):\n",
        "        idx = idxs[0]\n",
        "    else:\n",
        "        idx = np.argmax(r)\n",
        "    thresh = t[idx] if idx < len(t) else 0.5\n",
        "    rec = r[idx]\n",
        "\n",
        "    best_recall[label] = rec\n",
        "    best_thresh[label] = thresh\n",
        "    print(f\"✅  Recall for '{label}': {rec:.2f} @ threshold {thresh:.2f}\")\n",
        "\n",
        "\n",
        "print(\"\\n### Summary of per-family recall and thresholds ###\")\n",
        "for label in classes:\n",
        "    print(f\"{label:12s} → recall: {best_recall[label]:.2f}, threshold: {best_thresh[label]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train distribution: Counter({'Benign': 20237, 'Ransomware': 2363, 'Spyware': 2076, 'Botnet': 1747, 'Trojan': 1438, 'Worm': 1123})\n",
            "Valid distribution: Counter({'Benign': 5060, 'Ransomware': 591, 'Spyware': 519, 'Botnet': 437, 'Trojan': 359, 'Worm': 281})\n",
            "\n",
            "--- Training detector for 'Benign' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Benign' detector trained (pos_weight=1.0)\n",
            "\n",
            "--- Training detector for 'Botnet' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Botnet' detector trained (pos_weight=1.0)\n",
            "\n",
            "--- Training detector for 'Ransomware' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Ransomware' detector trained (pos_weight=1.0)\n",
            "\n",
            "--- Training detector for 'Spyware' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Spyware' detector trained (pos_weight=1.0)\n",
            "\n",
            "--- Training detector for 'Trojan' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Trojan' detector trained (pos_weight=1.0)\n",
            "\n",
            "--- Training detector for 'Worm' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [23:31:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Worm' detector trained (pos_weight=1.0)\n",
            "\n",
            "--- Tuning threshold for 'Benign' ---\n",
            "Chosen thr=0.582 → recall=0.54, precision=0.70\n",
            "\n",
            "--- Tuning threshold for 'Botnet' ---\n",
            "Chosen thr=0.016 → recall=0.96, precision=0.06\n",
            "\n",
            "--- Tuning threshold for 'Ransomware' ---\n",
            "Chosen thr=0.023 → recall=0.95, precision=0.08\n",
            "\n",
            "--- Tuning threshold for 'Spyware' ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chosen thr=0.028 → recall=0.93, precision=0.07\n",
            "\n",
            "--- Tuning threshold for 'Trojan' ---\n",
            "Chosen thr=0.325 → recall=0.25, precision=0.06\n",
            "\n",
            "--- Tuning threshold for 'Worm' ---\n",
            "Chosen thr=0.013 → recall=0.89, precision=0.04\n",
            "\n",
            "=== Summary ===\n",
            "Benign      : thr=0.582, recall=0.54, precision=0.70\n",
            "Botnet      : thr=0.016, recall=0.96, precision=0.06\n",
            "Ransomware  : thr=0.023, recall=0.95, precision=0.08\n",
            "Spyware     : thr=0.028, recall=0.93, precision=0.07\n",
            "Trojan      : thr=0.325, recall=0.25, precision=0.06\n",
            "Worm        : thr=0.013, recall=0.89, precision=0.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2676: UserWarning: [23:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import precision_recall_curve, recall_score\n",
        "\n",
        "\n",
        "print(\"Train distribution:\", Counter(y_train))\n",
        "print(\"Valid distribution:\", Counter(y_valid))\n",
        "\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "\n",
        "classifiers = {}\n",
        "for label in classes:\n",
        "    print(f\"\\n--- Training detector for '{label}' ---\")\n",
        "    y_bin     = (y_train == label).astype(int)\n",
        "    y_val_bin = (y_valid == label).astype(int)\n",
        "    if y_bin.sum() == 0:\n",
        "        print(f\"No samples for '{label}', skipping.\")\n",
        "        continue\n",
        "\n",
        "    \n",
        "    x_res, y_res = sm.fit_resample(x_train, y_bin)\n",
        "    neg, pos = np.bincount(y_res)\n",
        "    pos_weight = neg / pos\n",
        "\n",
        "    clf = XGBClassifier(\n",
        "        tree_method='gpu_hist',\n",
        "        predictor='gpu_predictor',\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        scale_pos_weight=pos_weight,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=500,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    clf.fit(x_res, y_res)\n",
        "    classifiers[label] = clf\n",
        "    print(f\"'{label}' detector trained (pos_weight={pos_weight:.1f})\")\n",
        "\n",
        "\n",
        "min_recall = 0.50\n",
        "min_precision = 0.10\n",
        "\n",
        "chosen_thresholds = {}\n",
        "results = {}\n",
        "\n",
        "for label, clf in classifiers.items():\n",
        "    print(f\"\\n--- Tuning threshold for '{label}' ---\")\n",
        "    y_val_bin = (y_valid == label).astype(int)\n",
        "    probs     = clf.predict_proba(x_valid)[:,1]\n",
        "    precisions, recalls, threshs = precision_recall_curve(y_val_bin, probs)\n",
        "\n",
        "    \n",
        "    valid_idxs = np.where((recalls >= min_recall) & (precisions >= min_precision))[0]\n",
        "    if len(valid_idxs):\n",
        "       \n",
        "        best_idx = valid_idxs[np.argmax(precisions[valid_idxs])]\n",
        "    else:\n",
        "        \n",
        "        f1_scores = 2 * precisions * recalls / (precisions + recalls + 1e-8)\n",
        "        best_idx = np.argmax(f1_scores)\n",
        "\n",
        "    thr = threshs[best_idx] if best_idx < len(threshs) else 0.5\n",
        "    rec = recalls[best_idx]\n",
        "    prec = precisions[best_idx]\n",
        "\n",
        "    chosen_thresholds[label] = thr\n",
        "    results[label] = {'recall': rec, 'precision': prec}\n",
        "    print(f\"Chosen thr={thr:.3f} → recall={rec:.2f}, precision={prec:.2f}\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "for label in classes:\n",
        "    if label in results:\n",
        "        r = results[label]\n",
        "        print(f\"{label:12s}: thr={chosen_thresholds[label]:.3f}, recall={r['recall']:.2f}, precision={r['precision']:.2f}\")\n",
        "    else:\n",
        "        print(f\"{label:12s}: no model trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thr=0.010 → recall=0.94, precision=0.05\n",
            "thr=0.020 → recall=0.85, precision=0.05\n",
            "thr=0.030 → recall=0.82, precision=0.05\n",
            "thr=0.040 → recall=0.78, precision=0.05\n",
            "thr=0.050 → recall=0.73, precision=0.05\n",
            "thr=0.060 → recall=0.69, precision=0.05\n",
            "thr=0.070 → recall=0.64, precision=0.05\n",
            "thr=0.080 → recall=0.60, precision=0.05\n",
            "thr=0.090 → recall=0.57, precision=0.05\n",
            "thr=0.100 → recall=0.55, precision=0.05\n",
            "thr=0.150 → recall=0.45, precision=0.05\n",
            "thr=0.200 → recall=0.36, precision=0.05\n",
            "thr=0.250 → recall=0.31, precision=0.06\n",
            "thr=0.300 → recall=0.26, precision=0.06\n",
            "thr=0.350 → recall=0.21, precision=0.06\n",
            "thr=0.400 → recall=0.16, precision=0.06\n",
            "thr=0.450 → recall=0.13, precision=0.06\n",
            "thr=0.500 → recall=0.09, precision=0.06\n",
            "\n",
            "Best threshold for Trojan: 0.010 → recall=0.94, precision=0.05\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "\n",
        "\n",
        "probs_trojan = classifiers['Trojan'].predict_proba(x_valid)[:, 1]\n",
        "\n",
        "\n",
        "y_val_trojan = (y_valid == 'Trojan').astype(int)\n",
        "\n",
        "\n",
        "thresholds = np.concatenate([\n",
        "    np.linspace(0.01, 0.10, 10),\n",
        "    np.linspace(0.15, 0.50, 8)\n",
        "])\n",
        "\n",
        "\n",
        "results = []\n",
        "for t in thresholds:\n",
        "    preds = (probs_trojan >= t).astype(int)\n",
        "    rec = recall_score(y_val_trojan, preds)\n",
        "    prec = precision_score(y_val_trojan, preds, zero_division=0)\n",
        "    results.append((t, rec, prec))\n",
        "    print(f\"thr={t:.3f} → recall={rec:.2f}, precision={prec:.2f}\")\n",
        "\n",
        "\n",
        "valid = [(t, rec, prec) for t, rec, prec in results if rec >= 0.50]\n",
        "if valid:\n",
        "    best_t, best_rec, best_prec = min(valid, key=lambda x: x[0])\n",
        "    print(f\"\\nBest threshold for Trojan: {best_t:.3f} → recall={best_rec:.2f}, precision={best_prec:.2f}\")\n",
        "else:\n",
        "    print(\"\\nNo threshold in the tested range achieves 50% recall.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Final Summary with manual Trojan override ===\n",
            "Benign      : thr=0.582, recall=0.54, precision=0.70\n",
            "Botnet      : thr=0.016, recall=0.96, precision=0.06\n",
            "Ransomware  : thr=0.023, recall=0.95, precision=0.08\n",
            "Spyware     : thr=0.028, recall=0.93, precision=0.07\n",
            "Trojan      : thr=0.010, recall=0.94, precision=0.05\n",
            "Worm        : thr=0.013, recall=0.89, precision=0.04\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score, precision_score\n",
        "\n",
        "\n",
        "chosen_thresholds['Trojan'] = 0.01\n",
        "print(\"\\n=== Final Summary with manual Trojan override ===\")\n",
        "for label, clf in classifiers.items():\n",
        "    thr   = chosen_thresholds[label]\n",
        "    y_bin = (y_valid == label).astype(int)\n",
        "    probs = clf.predict_proba(x_valid)[:,1]\n",
        "    preds = (probs >= thr).astype(int)\n",
        "    \n",
        "    rec  = recall_score(y_bin, preds)\n",
        "    prec = precision_score(y_bin, preds, zero_division=0)\n",
        "    print(f\"{label:12s}: thr={thr:.3f}, recall={rec:.2f}, precision={prec:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶️ Re-tuning thresholds for min_recall=0.5, min_precision=0.2\n",
            "\n",
            "--- Benign ---\n",
            "thr=0.582 → recall=0.54, precision=0.70\n",
            "--- Botnet ---\n",
            "thr=0.016 → recall=0.96, precision=0.06\n",
            "--- Ransomware ---\n",
            "thr=0.023 → recall=0.95, precision=0.08\n",
            "--- Spyware ---\n",
            "thr=0.028 → recall=0.93, precision=0.07\n",
            "--- Trojan ---\n",
            "thr=0.325 → recall=0.25, precision=0.06\n",
            "--- Worm ---\n",
            "thr=0.013 → recall=0.89, precision=0.04\n",
            "\n",
            "=== New per-family summary ===\n",
            "Benign       → thr=0.582, recall=0.54, precision=0.70\n",
            "Botnet       → thr=0.016, recall=0.96, precision=0.06\n",
            "Ransomware   → thr=0.023, recall=0.95, precision=0.08\n",
            "Spyware      → thr=0.028, recall=0.93, precision=0.07\n",
            "Trojan       → thr=0.325, recall=0.25, precision=0.06\n",
            "Worm         → thr=0.013, recall=0.89, precision=0.04\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, recall_score, precision_score\n",
        "min_recall    = 0.50\n",
        "min_precision = 0.20   \n",
        "\n",
        "new_thresholds = {}\n",
        "new_results    = {}\n",
        "\n",
        "print(f\"▶️ Re-tuning thresholds for min_recall={min_recall}, min_precision={min_precision}\\n\")\n",
        "\n",
        "for label, clf in classifiers.items():\n",
        "    print(f\"--- {label} ---\")\n",
        "    y_val_bin = (y_valid == label).astype(int)\n",
        "    probs     = clf.predict_proba(x_valid)[:,1]\n",
        "    precisions, recalls, threshs = precision_recall_curve(y_val_bin, probs)\n",
        "    valid_idxs = np.where((recalls >= min_recall) & (precisions >= min_precision))[0]\n",
        "\n",
        "    if len(valid_idxs):\n",
        "        best_idx = valid_idxs[np.argmax(precisions[valid_idxs])]\n",
        "    else:\n",
        "        f1s      = 2 * precisions * recalls / (precisions + recalls + 1e-8)\n",
        "        best_idx = np.argmax(f1s)\n",
        "\n",
        "    thr  = threshs[best_idx] if best_idx < len(threshs) else 0.5\n",
        "    rec  = recalls[best_idx]\n",
        "    prec = precisions[best_idx]\n",
        "\n",
        "    new_thresholds[label] = thr\n",
        "    new_results[label]    = (rec, prec)\n",
        "    print(f\"thr={thr:.3f} → recall={rec:.2f}, precision={prec:.2f}\")\n",
        "\n",
        "\n",
        "print(\"\\n=== New per-family summary ===\")\n",
        "for label in classifiers:\n",
        "    rec, prec = new_results[label]\n",
        "    print(f\"{label:12s} → thr={new_thresholds[label]:.3f}, recall={rec:.2f}, precision={prec:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶️ Calibrating classifiers with sigmoid Platt scaling (3-fold CV)…\n",
            "  • Calibrating 'Benign'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\calibration.py:300: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  • Calibrating 'Botnet'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\calibration.py:300: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  • Calibrating 'Ransomware'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\calibration.py:300: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  • Calibrating 'Spyware'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\calibration.py:300: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  • Calibrating 'Trojan'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\calibration.py:300: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  • Calibrating 'Worm'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\calibration.py:300: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "C:\\Users\\anant\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Calibration complete.\n",
            "\n",
            "▶️ Re-tuning thresholds for min_recall=0.4, min_precision=0.15\n",
            "\n",
            "--- Benign ---\n",
            "thr=0.700 → recall=0.40, precision=0.85\n",
            "--- Botnet ---\n",
            "thr=0.063 → recall=0.41, precision=0.29\n",
            "--- Ransomware ---\n",
            "thr=0.086 → recall=0.43, precision=0.31\n",
            "--- Spyware ---\n",
            "thr=0.075 → recall=0.40, precision=0.28\n",
            "--- Trojan ---\n",
            "thr=0.052 → recall=0.45, precision=0.28\n",
            "--- Worm ---\n",
            "thr=0.042 → recall=0.41, precision=0.43\n",
            "\n",
            "=== New per-family summary with calibration ===\n",
            "Benign       → thr=0.700, recall=0.40, precision=0.85\n",
            "Botnet       → thr=0.063, recall=0.41, precision=0.29\n",
            "Ransomware   → thr=0.086, recall=0.43, precision=0.31\n",
            "Spyware      → thr=0.075, recall=0.40, precision=0.28\n",
            "Trojan       → thr=0.052, recall=0.45, precision=0.28\n",
            "Worm         → thr=0.042, recall=0.41, precision=0.43\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import precision_recall_curve, recall_score, precision_score\n",
        "\n",
        "\n",
        "print(\" Calibrating classifiers with sigmoid Platt scaling (3-fold CV)…\")\n",
        "calibrated_clfs = {}\n",
        "for label, clf in classifiers.items():\n",
        "    print(f\"  • Calibrating '{label}'\")\n",
        "    calibrator = CalibratedClassifierCV(\n",
        "        base_estimator=clf,\n",
        "        method='isotonic',  \n",
        "        cv=3\n",
        "    )\n",
        "    \n",
        "    y_bin = (y_train == label).astype(int)\n",
        "    calibrator.fit(x_train, y_bin)\n",
        "    calibrated_clfs[label] = calibrator\n",
        "print(\"  Calibration complete.\\n\")\n",
        "\n",
        "\n",
        "classifiers = calibrated_clfs\n",
        "\n",
        "\n",
        "min_recall    = 0.40\n",
        "min_precision = 0.15\n",
        "\n",
        "new_thresholds = {}\n",
        "new_results    = {}\n",
        "\n",
        "print(f\" Re-tuning thresholds for min_recall={min_recall}, min_precision={min_precision}\\n\")\n",
        "for label, clf in classifiers.items():\n",
        "    print(f\"--- {label} ---\")\n",
        "    y_val_bin = (y_valid == label).astype(int)\n",
        "    probs     = clf.predict_proba(x_valid)[:,1]\n",
        "\n",
        "    precisions, recalls, threshs = precision_recall_curve(y_val_bin, probs)\n",
        "    valid_idxs = np.where((recalls >= min_recall) & (precisions >= min_precision))[0]\n",
        "\n",
        "    if len(valid_idxs):\n",
        "        best_idx = valid_idxs[np.argmax(precisions[valid_idxs])]\n",
        "    else:\n",
        "        f1s      = 2 * precisions * recalls / (precisions + recalls + 1e-8)\n",
        "        best_idx = np.argmax(f1s)\n",
        "\n",
        "    thr  = threshs[best_idx] if best_idx < len(threshs) else 0.5\n",
        "    rec  = recalls[best_idx]\n",
        "    prec = precisions[best_idx]\n",
        "\n",
        "    new_thresholds[label] = thr\n",
        "    new_results[label]    = (rec, prec)\n",
        "    print(f\"thr={thr:.3f} → recall={rec:.2f}, precision={prec:.2f}\")\n",
        "\n",
        "print(\"\\n=== New per-family summary with calibration ===\")\n",
        "for label in classifiers:\n",
        "    rec, prec = new_results[label]\n",
        "    print(f\"{label:12s} → thr={new_thresholds[label]:.3f}, recall={rec:.2f}, precision={prec:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Final per-family classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.78      0.82      0.80      5060\n",
            "      Botnet       0.32      0.36      0.34       437\n",
            "  Ransomware       0.36      0.34      0.35       591\n",
            "     Spyware       0.34      0.28      0.30       519\n",
            "      Trojan       0.35      0.26      0.30       359\n",
            "        Worm       0.43      0.28      0.34       281\n",
            "\n",
            "    accuracy                           0.67      7247\n",
            "   macro avg       0.43      0.39      0.40      7247\n",
            "weighted avg       0.65      0.67      0.66      7247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "final_thresholds = {\n",
        "    'Benign'     : 0.700,\n",
        "    'Botnet'     : 0.063,\n",
        "    'Ransomware' : 0.086,\n",
        "    'Spyware'    : 0.075,\n",
        "    'Trojan'     : 0.052,\n",
        "    'Worm'       : 0.042\n",
        "}\n",
        "\n",
        "\n",
        "y_pred_final = []\n",
        "for xi in x_valid_imp:\n",
        "    #calibrated possibilities\n",
        "    probs = {\n",
        "        lbl: clf.predict_proba(xi.reshape(1, -1))[0,1]\n",
        "        for lbl, clf in classifiers.items()\n",
        "    }\n",
        "    hits = [lbl for lbl, p in probs.items() if p >= final_thresholds[lbl]]\n",
        "    if hits:\n",
        "        y_pred_final.append(hits[0])\n",
        "    else:\n",
        "        #picking max probability family\n",
        "        y_pred_final.append(max(probs, key=probs.get))\n",
        "\n",
        "print(\" Final per-family classification report:\\n\")\n",
        "print(classification_report(y_valid, y_pred_final, digits=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thresholds.json']"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(classifiers, 'family_detectors.pkl')\n",
        "joblib.dump(final_thresholds, 'thresholds.json')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
